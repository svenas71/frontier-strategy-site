---
layout: layouts/post.njk
title: "What LLMs will teach us about the Mind"
date: 2024-03-12
summary: "Beyond chat: LLMs are our first toolbox for cognition"
type: post
tags: [signal]
---


It is rare that a new epoch begins with version 3.5. Yet this was the case with ChatGPT, which went public in November of 2022, where it was already past its third major iteration.

It is now of course mainstream and in everybody’s conversations, synonymous with AI, LLMs and the future of computing in general, so it seems.

I started using ChatGPT right away, testing it, letting it write tedious work for me and just taking it for a spin. I was amazed, enthralled and found it to be an incredibly useful tool. Me and at least another 100 million people, too, that is.

The ability of ChatGPT to write cogent sentences was astonishing. The ease with which it would collate information on complex topics was a massive time saver. The fluency it showed was awe inspiring. These were all features that made the term ‘artificial intelligence’ seem apt.

To a point, that is — as has been well documented: hallucinations, simple errors, lack of reasoning, inability to do maths or count accurately. This below is an example I typed into the chatbot two minutes ago:

You: How often does the letter ‘e’ appear in the word seven
ChatGPT: The letter ‘e’ appears only once in the word “seven”

This is clearly not intelligent. It is plain dumb. Impressive, but wrong.

It was around November of 2023, one year after its public debut, that I attended a talk by a Google engineer at an AI consultancy here in Berlin. The talk was about how one could use Google’s platform to generate one’s own chatbot.

The interesting part came after the talk — over pizza and beverages. One person in attendance had been asking very specific and detailed questions about Google’s plans to update the model. What would be on the horizon, what would the next features look like, things like that.

The Google engineer dodged the questions. As much as most of the audience would have liked to know what was on Google’s product roadmap, this engineer was in no position to divulge that information. Rightly so, I thought to myself. I have been in product management myself, and there is no way we would have divulged unreleased features in a public setting.

So I went up to said gentleman over drinks and pizza. It turns out he was one of the partners at said consultancy, the host venue of the evening. We started talking. As we were talking about the future, I said, looking far ahead, these language models, evolved, would enable us to ask really deep questions about our own cognition. How do we learn, how do we understand, how does sentience occur.

It was the first time in human history — my thesis — that we had created a system in which we could experimentally and functionally ask these questions. We hadn’t just created a chatbot, we had made the very first version of a controllable experimental system to study the mind.

A while ago I tweeted: we will see sentient AI within a decade. I think that is entirely possible. It will not only advance computer science, but also our understanding of sentience and consciousness. This — to me — is the true breakthrough of what we are seeing unfold before us right now.